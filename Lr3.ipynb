{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffdd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef0b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'sci.crypt', 'sci.electronics']\n",
    "remove = ['headers', 'footers', 'quotes']\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4eca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = pd.DataFrame(twenty_train, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)\n",
    "twenty_test = pd.DataFrame(twenty_test, columns=['data', 'target']).replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0e8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    nltk_tokens = word_tokenize(data)\n",
    "    line = ''\n",
    "    for word in nltk_tokens:\n",
    "        line += ' ' + porter_stemmer.stem(word)\n",
    "    return line\n",
    "\n",
    "twenty_train.insert(loc=1, column='data_stemmed', value=twenty_train['data'].apply(lambda text: stemming(text)))\n",
    "twenty_test.insert(loc=1, column='data_stemmed', value=twenty_test['data'].apply(lambda text: stemming(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f347ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings \n",
    "from sklearn.exceptions import FitFailedWarning, ConvergenceWarning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e4f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to 0.0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.4 s\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "    'SVC': [{\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "    },\n",
    "        {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "    }],\n",
    "    'RandomForestClassifier': {\n",
    "            'vect__max_features': (1000,5000,10000),\n",
    "            'vect__stop_words': ('english', None),\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__criterion': ['gini','entropy','log_loss'],\n",
    "            'clf__max_depth': [3,5,10,None]\n",
    "    },\n",
    "    'LinearSVC': [{\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__loss': ['squared_hinge'],\n",
    "        'clf__penalty': ('l1', 'l2')\n",
    "    },\n",
    "        {\n",
    "        'vect__max_features': (1000,5000,10000),\n",
    "        'vect__stop_words': ('english', None),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__loss': ['hinge'],\n",
    "        'clf__penalty': ['l2']\n",
    "    }],\n",
    "}\n",
    "\n",
    "gs = {}\n",
    "for clf, param in parameters.items():\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', eval(clf)())\n",
    "    ])\n",
    "    gs[clf] = GridSearchCV(text_clf, param, n_jobs=-1, error_score=0.0)\n",
    "    gs[clf].fit(X = twenty_train['data'], y = twenty_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa71e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  comp.graphics       0.82      0.85      0.83       389\n",
      "      sci.crypt       0.92      0.74      0.82       396\n",
      "sci.electronics       0.72      0.84      0.78       393\n",
      "\n",
      "       accuracy                           0.81      1178\n",
      "      macro avg       0.82      0.81      0.81      1178\n",
      "   weighted avg       0.82      0.81      0.81      1178\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  comp.graphics       0.75      0.85      0.79       389\n",
      "      sci.crypt       0.88      0.74      0.81       396\n",
      "sci.electronics       0.72      0.73      0.72       393\n",
      "\n",
      "       accuracy                           0.77      1178\n",
      "      macro avg       0.78      0.77      0.77      1178\n",
      "   weighted avg       0.78      0.77      0.77      1178\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  comp.graphics       0.80      0.86      0.83       389\n",
      "      sci.crypt       0.87      0.80      0.84       396\n",
      "sci.electronics       0.78      0.79      0.79       393\n",
      "\n",
      "       accuracy                           0.82      1178\n",
      "      macro avg       0.82      0.82      0.82      1178\n",
      "   weighted avg       0.82      0.82      0.82      1178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    print(metrics.classification_report(twenty_test.target, predicted, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f8b7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {}\n",
    "def highlight_max(x, color):\n",
    "\n",
    "    return np.where(x == np.nanmax(x.to_numpy()), f\"color: {color};\", None)\n",
    "\n",
    "total_style = pd.Series(\"font-weight: bold;\", index=[1])\n",
    "\n",
    "for clf, param in parameters.items():\n",
    "    predicted = gs[clf].predict(twenty_test['data'])\n",
    "    \n",
    "    pd.DataFrame(gs[clf].cv_results_).to_excel('all' + clf + '.xlsx')\n",
    "    pd.DataFrame(classification_report(predicted, twenty_test.target, output_dict=True)).to_excel('best' + clf + '.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829b685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
